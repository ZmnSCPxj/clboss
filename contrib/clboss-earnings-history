#!/usr/bin/env python3

import os
import subprocess
import argparse
import json
import csv
from datetime import datetime
from tabulate import tabulate
from clboss.alias_cache import lookup_alias, is_nodeid, lookup_nodeid_by_alias

def run_lightning_cli_command(lightning_dir, network_option, command, *args):
    try:
        command = ['lightning-cli', network_option, command, *args]
        if lightning_dir:
            command = command[:2] + [f'--lightning-dir={lightning_dir}'] + command[2:]
        result = subprocess.run(command,
                                capture_output=True,
                                text=True,
                                check=True)
        return json.loads(result.stdout)
    except subprocess.CalledProcessError as e:
        print(f"Command '{command}' failed with error: {e}")
    except json.JSONDecodeError as e:
        print(f"Failed to parse JSON from command '{command}': {e}")
    return None

def format_bucket_time(bucket_time):
    if bucket_time == 0:
        return "Legacy"
    else:
        return datetime.utcfromtimestamp(bucket_time).strftime('%Y-%m-%d')

def bucket_key(ds, bucket):
    if ds == "Legacy":
        return ds
    dt = datetime.strptime(ds, '%Y-%m-%d')
    if bucket == 'day':
        return dt.strftime('%Y-%m-%d')
    elif bucket == 'week':
        iso = dt.isocalendar()
        return f"{iso[0]}-W{iso[1]:02d}"
    elif bucket == 'month':
        return dt.strftime('%Y-%m')
    else:  # quarter
        q = (dt.month - 1)//3 + 1
        return f"{dt.year}-Q{q}"

def main():
    parser = argparse.ArgumentParser(description="Run lightning-cli with specified network")
    parser.add_argument('--mainnet', action='store_true', help='Run on mainnet')
    parser.add_argument('--testnet', action='store_true', help='Run on testnet')
    parser.add_argument('--signet', action='store_true', help='Run on signet')
    parser.add_argument('--regtest', action='store_true', help='Run on regtest')
    parser.add_argument('--network', help='Set the network explicitly')

    parser.add_argument('nodeid_or_alias', nargs='?',
                        help='The node ID (or alias) to pass to clboss-earnings-history (optional)')

    parser.add_argument('--lightning-dir', help='lightning data location')

    parser.add_argument('--csv-file', help='Write raw data to the given CSV file')
    parser.add_argument('--graph-file', help='Write a PNG graph of net earnings')
    parser.add_argument('--bucket', dest='bucket', default='day',
                        choices=['day','week','month','quarter'],
                        help='Aggregation period for table and graph')

    args = parser.parse_args()

    # Reconcile network option
    if args.network:
        network_option = f'--network={args.network}'
    elif args.testnet:
        network_option = '--network=testnet'
    elif args.signet:
        network_option = '--network=signet'
    elif args.regtest:
        network_option = '--network=regtest'
    else:
        network_option = '--network=bitcoin'	# lightning-cli wants "bitcoin" for mainnet

    if args.lightning_dir:
        lightning_dir = args.lightning_dir
        assert os.path.isdir(lightning_dir), f'"{lightning_dir}" is not a valid directory'
    else:
        lightning_dir = None

    alias = None
    nodeid = None
    if args.nodeid_or_alias:
        # Determine if input is a nodeid or alias
        if is_nodeid(args.nodeid_or_alias):  # Check if it's a node ID
            nodeid = args.nodeid_or_alias
            alias = lookup_alias(run_lightning_cli_command, lightning_dir, network_option, nodeid)
        else:  # It's an alias, so look it up
            alias = args.nodeid_or_alias
            nodeid = lookup_nodeid_by_alias(run_lightning_cli_command, lightning_dir, network_option, alias)
            if not nodeid:
                print(f"Error: Alias '{alias}' not found.")
                return

    earnings_data = run_lightning_cli_command(
        lightning_dir, network_option, 'clboss-earnings-history', nodeid or "")

    # Initialize totals
    total_net_earnings = 0
    total_in_earnings = 0
    total_in_forwarded = 0
    total_in_expenditures = 0
    total_in_rebalanced = 0
    total_out_earnings = 0
    total_out_forwarded = 0
    total_out_expenditures = 0
    total_out_rebalanced = 0

    # Process and format data
    rows = []
    csv_rows = []
    bucket_data = {}
    bucket_order = []
    for entry in earnings_data['history']:
        in_earnings = entry['in_earnings']
        in_forwarded = entry['in_forwarded']
        in_expenditures = entry['in_expenditures']
        in_rebalanced = entry['in_rebalanced']

        out_earnings = entry['out_earnings']
        out_forwarded = entry['out_forwarded']
        out_expenditures = entry['out_expenditures']
        out_rebalanced = entry['out_rebalanced']

        date_str = format_bucket_time(entry['bucket_time'])
        key = bucket_key(date_str, args.bucket)
        if key not in bucket_data:
            bucket_data[key] = {
                'in_earnings': 0,
                'in_forwarded': 0,
                'in_expenditures': 0,
                'in_rebalanced': 0,
                'out_earnings': 0,
                'out_forwarded': 0,
                'out_expenditures': 0,
                'out_rebalanced': 0,
            }
            bucket_order.append(key)

        bucket_data[key]['in_earnings'] += in_earnings
        bucket_data[key]['in_forwarded'] += in_forwarded
        bucket_data[key]['in_expenditures'] += in_expenditures
        bucket_data[key]['in_rebalanced'] += in_rebalanced
        bucket_data[key]['out_earnings'] += out_earnings
        bucket_data[key]['out_forwarded'] += out_forwarded
        bucket_data[key]['out_expenditures'] += out_expenditures
        bucket_data[key]['out_rebalanced'] += out_rebalanced

        total_in_earnings += in_earnings
        total_in_forwarded += in_forwarded
        total_in_expenditures += in_expenditures
        total_in_rebalanced += in_rebalanced
        total_out_earnings += out_earnings
        total_out_forwarded += out_forwarded
        total_out_expenditures += out_expenditures
        total_out_rebalanced += out_rebalanced

        if args.nodeid_or_alias:
            net_earnings = (in_earnings + out_earnings) - (in_expenditures + out_expenditures)
        else:
            net_earnings = in_earnings - in_expenditures
        total_net_earnings += net_earnings

    for key in bucket_order:
        data = bucket_data[key]
        in_earnings = data['in_earnings']
        in_forwarded = data['in_forwarded']
        in_expenditures = data['in_expenditures']
        in_rebalanced = data['in_rebalanced']
        out_earnings = data['out_earnings']
        out_forwarded = data['out_forwarded']
        out_expenditures = data['out_expenditures']
        out_rebalanced = data['out_rebalanced']

        in_forwarded_rate = (
            (in_earnings / in_forwarded) * 1_000_000 if in_forwarded != 0 else 0
        )
        in_rebalance_rate = (
            (in_expenditures / in_rebalanced) * 1_000_000 if in_rebalanced != 0 else 0
        )
        out_forwarded_rate = (
            (out_earnings / out_forwarded) * 1_000_000 if out_forwarded != 0 else 0
        )
        out_rebalance_rate = (
            (out_expenditures / out_rebalanced) * 1_000_000 if out_rebalanced != 0 else 0
        )

        if args.nodeid_or_alias:
            net_earnings = (in_earnings + out_earnings) - (in_expenditures + out_expenditures)
        else:
            net_earnings = in_earnings - in_expenditures

        date_str = key

        if args.nodeid_or_alias:
            rows.append([
                date_str,
                f"{in_forwarded:,}".replace(',', '_'),
                f"{in_forwarded_rate:,.0f}",
                f"{in_earnings:,}".replace(',', '_'),
                f"{out_forwarded:,}".replace(',', '_'),
                f"{out_forwarded_rate:,.0f}",
                f"{out_earnings:,}".replace(',', '_'),
                f"{in_rebalanced:,}".replace(',', '_'),
                f"{in_rebalance_rate:,.0f}",
                f"{in_expenditures:,}".replace(',', '_'),
                f"{out_rebalanced:,}".replace(',', '_'),
                f"{out_rebalance_rate:,.0f}",
                f"{out_expenditures:,}".replace(',', '_'),
                f"{int(net_earnings):,}".replace(',', '_')
            ])
            csv_rows.append([
                date_str,
                in_forwarded,
                round(in_forwarded_rate, 0),
                in_earnings,
                out_forwarded,
                round(out_forwarded_rate, 0),
                out_earnings,
                in_rebalanced,
                round(in_rebalance_rate, 0),
                in_expenditures,
                out_rebalanced,
                round(out_rebalance_rate, 0),
                out_expenditures,
                int(net_earnings)
            ])
        else:
            rows.append([
                date_str,
                f"{in_forwarded:,}".replace(',', '_'),
                f"{in_forwarded_rate:,.0f}",
                f"{in_earnings:,}".replace(',', '_'),
                f"{in_rebalanced:,}".replace(',', '_'),
                f"{in_rebalance_rate:,.0f}",
                f"{in_expenditures:,}".replace(',', '_'),
                f"{int(net_earnings):,}".replace(',', '_')
            ])
            csv_rows.append([
                date_str,
                in_forwarded,
                round(in_forwarded_rate, 0),
                in_earnings,
                in_rebalanced,
                round(in_rebalance_rate, 0),
                in_expenditures,
                int(net_earnings)
            ])

    # Add a header (separator) row
    if args.nodeid_or_alias:
        # Show both the incoming and outgoing statistics
        headers = [
            "Date",
            "In Forwarded",
            "PPM",
            "In Earnings",
            "Out Forwarded",
            "PPM",
            "Out Earnings",
            "In Rebalanced",
            "PPM",
            "In Expense",
            "Out Rebalanced",
            "PPM",
            "Out Expense",
            "Net Earnings"
        ]
    else:
        # Incoming and outgoing are always the same (balanced)
        headers = [
            "Date",
            "Forwarded",
            "PPM",
            "Earnings",
            "Rebalanced",
            "PPM",
            "Expense",
            "Net Earnings"
        ]

    # Make a separator row before the totals
    rows.append(["-" * len(header) for header in headers])

    # Append the total row
    if args.nodeid_or_alias:
	# Show both the incoming and outgoing statistics
        rows.append([
            "TOTAL",
            f"{total_in_forwarded:,}".replace(',', '_'),
            # misleading because legacy numerator only: f"{total_in_forwarded_rate:,.0f}",
            f"",
            f"{total_in_earnings:,}".replace(',', '_'),
            f"{total_out_forwarded:,}".replace(',', '_'),
            # misleading because legacy numerator only: f"{total_out_forwarded_rate:,.0f}",
            f"",
            f"{total_out_earnings:,}".replace(',', '_'),
            f"{total_in_rebalanced:,}".replace(',', '_'),
            # misleading because legacy: f"{total_in_rebalance_rate:,.0f}",
            f"",
            f"{total_in_expenditures:,}".replace(',', '_'),
            f"{total_out_rebalanced:,}".replace(',', '_'),
            # misleading because legacy: f"{total_out_rebalance_rate:,.0f}",
            f"",
            f"{total_out_expenditures:,}".replace(',', '_'),
            f"{int(total_net_earnings):,}".replace(',', '_')
        ])
        csv_rows.append([
            "TOTAL",
            total_in_forwarded,
            "",
            total_in_earnings,
            total_out_forwarded,
            "",
            total_out_earnings,
            total_in_rebalanced,
            "",
            total_in_expenditures,
            total_out_rebalanced,
            "",
            total_out_expenditures,
            int(total_net_earnings)
        ])
    else:
        # Incoming and outgoing are always the same (balanced)
        rows.append([
            "TOTAL",
            f"{total_in_forwarded:,}".replace(',', '_'),
            # misleading because legacy: f"{total_in_forwarded_rate:,.0f}",
            f"",
            f"{total_in_earnings:,}".replace(',', '_'),
            f"{total_in_rebalanced:,}".replace(',', '_'),
            # misleading because legacy: f"{total_in_rebalance_rate:,.0f}",
            f"",
            f"{total_in_expenditures:,}".replace(',', '_'),
            f"{int(total_net_earnings):,}".replace(',', '_')
        ])
        csv_rows.append([
            "TOTAL",
            total_in_forwarded,
            "",
            total_in_earnings,
            total_in_rebalanced,
            "",
            total_in_expenditures,
            int(total_net_earnings)
        ])

    if args.nodeid_or_alias:
        print(f"Showing history for {nodeid} aka {alias}")

    print(tabulate(rows, headers=headers, tablefmt="pretty", stralign="right", numalign="right"))

    if args.csv_file:
        with open(args.csv_file, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(headers)
            writer.writerows(csv_rows)
        print(f"Wrote CSV data to {args.csv_file}")

    if args.graph_file:
        try:
            import matplotlib.pyplot as plt
        except ImportError:
            print("matplotlib is required to output graphs. Please install it.")
        else:
            def period_key(ds):
                if ds in ("Legacy", "TOTAL"):
                    return None
                return ds

            agg = {}
            for row in csv_rows:
                key = period_key(row[0])
                if key is None:
                    continue
                agg[key] = agg.get(key, 0) + row[-1]

            if not agg:
                print("No data to plot")
            else:
                labels = sorted(agg.keys())
                values = [agg[k] for k in labels]
                plt.figure(figsize=(10, 6))
                plt.plot(labels, values, marker='o')
                plt.xlabel(args.bucket.capitalize())
                plt.ylabel('Net Earnings (msats)')
                plt.title('CLBOSS Earnings History')
                plt.xticks(rotation=45, ha='right')
                plt.tight_layout()
                plt.grid(True)
                plt.savefig(args.graph_file)
                plt.close()
                print(f"Wrote graph to {args.graph_file}")

if __name__ == "__main__":
    main()
